{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ3Vce1g5skW"
      },
      "source": [
        "# Practical Application III: Comparing Classifiers\n",
        "\n",
        "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxqVhtG95skX"
      },
      "source": [
        "### Getting Started\n",
        "\n",
        "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6flHiKz5skX"
      },
      "source": [
        "### Problem 1: Understanding the Data\n",
        "\n",
        "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5hU6G6m5skX"
      },
      "outputs": [],
      "source": [
        "# For p1 after reading the paper, I cannot figure out the exact number of marketing compaigns presented. However, I saw there are three iterations in the compaign loop\n",
        "# the first one is to define the goal with its business understanding phase,\n",
        "# the second one is to try optimize the number of classification labels by redefining the goal\n",
        "# the third one is to minimize the dimensionality of parameters considered for training in order to fit more models and algos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm6mCb8X5skX"
      },
      "source": [
        "### Problem 2: Read in the Data\n",
        "\n",
        "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DvtiwAqE5skX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lad7LRuT5skY"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n4VeEZ3x5skY"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>...</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   age        job  marital    education  default housing loan    contact  \\\n",
              "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
              "1   57   services  married  high.school  unknown      no   no  telephone   \n",
              "2   37   services  married  high.school       no     yes   no  telephone   \n",
              "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
              "4   56   services  married  high.school       no      no  yes  telephone   \n",
              "\n",
              "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
              "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "\n",
              "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
              "0          93.994          -36.4      4.857       5191.0  no  \n",
              "1          93.994          -36.4      4.857       5191.0  no  \n",
              "2          93.994          -36.4      4.857       5191.0  no  \n",
              "3          93.994          -36.4      4.857       5191.0  no  \n",
              "4          93.994          -36.4      4.857       5191.0  no  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEwfsbGF5skY"
      },
      "source": [
        "### Problem 3: Understanding the Features\n",
        "\n",
        "\n",
        "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
        "\n",
        "\n",
        "```\n",
        "Input variables:\n",
        "# bank client data:\n",
        "1 - age (numeric)\n",
        "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
        "# related with the last contact of the current campaign:\n",
        "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
        "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "# other attributes:\n",
        "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
        "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "# social and economic context attributes\n",
        "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
        "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
        "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
        "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
        "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
        "\n",
        "Output variable (desired target):\n",
        "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "caB01hl35skY"
      },
      "outputs": [],
      "source": [
        "# we can replace all the unknowns with nan in order to void them\n",
        "df.replace('unknown', pd.NA,inplace=True)\n",
        "\n",
        "# for the numerica data, we can keep it as it is. For those categorical datas, it's actually stored as object, we can convert it to category type.\n",
        "categorical_cols = [\n",
        "    'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
        "    'contact', 'month', 'day_of_week', 'poutcome',\n",
        "]\n",
        "df[categorical_cols] = df[categorical_cols].astype('category')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r0mVdg35skY"
      },
      "source": [
        "### Problem 4: Understanding the Task\n",
        "\n",
        "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9Qb0ZED5skY",
        "outputId": "9c5e122e-7fc0-431d-c0dc-8ea0cdb30b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41188 entries, 0 to 41187\n",
            "Data columns (total 21 columns):\n",
            " #   Column          Non-Null Count  Dtype   \n",
            "---  ------          --------------  -----   \n",
            " 0   age             41188 non-null  int64   \n",
            " 1   job             40858 non-null  category\n",
            " 2   marital         41108 non-null  category\n",
            " 3   education       39457 non-null  category\n",
            " 4   default         32591 non-null  category\n",
            " 5   housing         40198 non-null  category\n",
            " 6   loan            40198 non-null  category\n",
            " 7   contact         41188 non-null  category\n",
            " 8   month           41188 non-null  category\n",
            " 9   day_of_week     41188 non-null  category\n",
            " 10  duration        41188 non-null  int64   \n",
            " 11  campaign        41188 non-null  int64   \n",
            " 12  pdays           41188 non-null  int64   \n",
            " 13  previous        41188 non-null  int64   \n",
            " 14  poutcome        41188 non-null  category\n",
            " 15  emp.var.rate    41188 non-null  float64 \n",
            " 16  cons.price.idx  41188 non-null  float64 \n",
            " 17  cons.conf.idx   41188 non-null  float64 \n",
            " 18  euribor3m       41188 non-null  float64 \n",
            " 19  nr.employed     41188 non-null  float64 \n",
            " 20  y               41188 non-null  object  \n",
            "dtypes: category(10), float64(5), int64(5), object(1)\n",
            "memory usage: 3.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZgZHJIf_5skZ"
      },
      "outputs": [],
      "source": [
        "# The goal will be to predict whether the client will subscribe the term deposit based on the datasets information given. We are aimed to train a model that helps us predict\n",
        "# client's decision on the subscriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pxi5N59v5skZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcqLUcJf5skZ"
      },
      "source": [
        "### Problem 5: Engineering Features\n",
        "\n",
        "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlkVP2ga5skZ",
        "outputId": "1703e95e-d729-4531-fabc-32f0339a7820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   duration  campaign  pdays  previous  job_blue-collar  job_entrepreneur  \\\n",
            "0       261         1    999         0            False             False   \n",
            "1       149         1    999         0            False             False   \n",
            "2       226         1    999         0            False             False   \n",
            "3       151         1    999         0            False             False   \n",
            "4       307         1    999         0            False             False   \n",
            "\n",
            "   job_housemaid  job_management  job_retired  job_self-employed  ...  \\\n",
            "0           True           False        False              False  ...   \n",
            "1          False           False        False              False  ...   \n",
            "2          False           False        False              False  ...   \n",
            "3          False           False        False              False  ...   \n",
            "4          False           False        False              False  ...   \n",
            "\n",
            "   education_basic.6y  education_basic.9y  education_high.school  \\\n",
            "0               False               False                  False   \n",
            "1               False               False                   True   \n",
            "2               False               False                   True   \n",
            "3                True               False                  False   \n",
            "4               False               False                   True   \n",
            "\n",
            "   education_illiterate  education_professional.course  \\\n",
            "0                 False                          False   \n",
            "1                 False                          False   \n",
            "2                 False                          False   \n",
            "3                 False                          False   \n",
            "4                 False                          False   \n",
            "\n",
            "   education_university.degree  housing_yes  loan_yes  poutcome_nonexistent  \\\n",
            "0                        False        False     False                  True   \n",
            "1                        False        False     False                  True   \n",
            "2                        False         True     False                  True   \n",
            "3                        False        False     False                  True   \n",
            "4                        False        False      True                  True   \n",
            "\n",
            "   poutcome_success  \n",
            "0             False  \n",
            "1             False  \n",
            "2             False  \n",
            "3             False  \n",
            "4             False  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: y, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# manually selected some possible related features for training\n",
        "selected_features = ['job','marital','education','housing','loan','duration','campaign','pdays','previous','poutcome']\n",
        "target = 'y'\n",
        "df = df[selected_features + [target]]\n",
        "\n",
        "# drop the missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "df_encoded = pd.get_dummies(df.drop(columns=target), drop_first=True)\n",
        "\n",
        "# Label encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded[target] = label_encoder.fit_transform(df[target])\n",
        "\n",
        "\n",
        "X = df_encoded.drop(columns=target)\n",
        "y = df_encoded[target]\n",
        "\n",
        "print(X.head())\n",
        "print(y.head())\n",
        "\n",
        "# now we have the encoded datasets that transform catogorical data columns with one hot encoding, and the result mapping of 0 or 1 as no or yes. We can begin exploring the training\n",
        "# steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "babUD6565skZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVAMGV5A5skZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4w8hg3T5skZ"
      },
      "source": [
        "### Problem 6: Train/Test Split\n",
        "\n",
        "With your data prepared, split it into a train and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL_Dkmo25skZ",
        "outputId": "a1b0e83a-4e7d-40e8-997d-45f9b6048e9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set: (30596, 26), (30596,)\n",
            "Test set:  (7649, 26), (7649,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# ensure that the size matches for train and test X,y\n",
        "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test set:  {X_test.shape}, {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x1pDDFM5skZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmpUiA3P5skZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAy4npq25skZ"
      },
      "source": [
        "### Problem 7: A Baseline Model\n",
        "\n",
        "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKnSNcvf5skZ",
        "outputId": "b3bc3811-c1cf-4512-89c8-2aea440929a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Accuracy: 0.8886\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      6797\n",
            "           1       0.00      0.00      0.00       852\n",
            "\n",
            "    accuracy                           0.89      7649\n",
            "   macro avg       0.44      0.50      0.47      7649\n",
            "weighted avg       0.79      0.89      0.84      7649\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jhw75\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\jhw75\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\jhw75\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "baseline = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
        "baseline.fit(X_train, y_train)\n",
        "\n",
        "y_pred_baseline = baseline.predict(X_test)\n",
        "\n",
        "# performance evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "print(f\"Baseline Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_baseline))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3H2qXfn5skZ"
      },
      "outputs": [],
      "source": [
        "# from the above code, the baseline model shows an accuracy of 0.8886, this would be the performance we aim to beat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHoHp1Sn5skZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvA7EFIj5skZ"
      },
      "source": [
        "### Problem 8: A Simple Model\n",
        "\n",
        "Use Logistic Regression to build a basic model on your data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmlNzByt5skZ",
        "outputId": "6e6b3faf-129c-49f4-f7a7-7d6aee9ba610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 1.06 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jhw75\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=1000) # Increased max_iter for convergence\n",
        "start_time_log_reg = time.time()\n",
        "log_reg.fit(X_train, y_train)\n",
        "end_time_log_reg = time.time()\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "time_trained_log_reg = end_time_log_reg - start_time_log_reg\n",
        "print(f\"Training Time: {time_trained_log_reg:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxoDZZT55skZ"
      },
      "source": [
        "### Problem 9: Score the Model\n",
        "\n",
        "What is the accuracy of your model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHm50THx5skZ",
        "outputId": "57ab0b16-861c-4678-a394-547a2b1538fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9056\n",
            "Logistic Regression Accuracy: 0.9068\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      6797\n",
            "           1       0.67      0.33      0.44       852\n",
            "\n",
            "    accuracy                           0.91      7649\n",
            "   macro avg       0.79      0.65      0.69      7649\n",
            "weighted avg       0.89      0.91      0.89      7649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# model evaluation\n",
        "train_accurarcy_log_reg = accuracy_score(y_train, log_reg.predict(X_train))\n",
        "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "print(f\"Training Accuracy: {train_accurarcy_log_reg:.4f}\")\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_log_reg:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_log_reg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADLaHDB_5skZ"
      },
      "source": [
        "### Problem 10: Model Comparisons\n",
        "\n",
        "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
        "\n",
        "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
        "| ----- | ---------- | -------------  | -----------   |\n",
        "|     |    |.     |.     |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru6ckDGf5skZ",
        "outputId": "6ec15276-589e-43a6-a773-533fe0bf1c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 0.01 seconds\n",
            "Training Accuracy: 0.9200\n",
            "KNN Accuracy: 0.8985\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94      6797\n",
            "           1       0.57      0.37      0.45       852\n",
            "\n",
            "    accuracy                           0.90      7649\n",
            "   macro avg       0.75      0.67      0.69      7649\n",
            "weighted avg       0.88      0.90      0.89      7649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# knn section\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
        "start_time_knn = time.time()\n",
        "knn_clf.fit(X_train, y_train)\n",
        "end_time_knn = time.time()\n",
        "y_pred_knn = knn_clf.predict(X_test)\n",
        "\n",
        "time_trained_knn = end_time_knn - start_time_knn\n",
        "print(f\"Training Time: {time_trained_knn:.2f} seconds\")\n",
        "\n",
        "# model evaluation\n",
        "train_accuracy_knn = accuracy_score(y_train, knn_clf.predict(X_train))\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"Training Accuracy: {train_accuracy_knn:.4f}\")\n",
        "print(f\"KNN Accuracy: {accuracy_knn:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_r6wTJA5skZ",
        "outputId": "a1494784-4558-478e-fb8d-fd23c48c6258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 5.38 seconds\n",
            "Training Accuracy: 0.9050\n",
            "SVM Accuracy: 0.9051\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.95      6797\n",
            "           1       0.69      0.27      0.39       852\n",
            "\n",
            "    accuracy                           0.91      7649\n",
            "   macro avg       0.80      0.63      0.67      7649\n",
            "weighted avg       0.89      0.91      0.89      7649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SVM section\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svm_clf = SVC(kernel='rbf', random_state=42)\n",
        "start_time_svm = time.time()\n",
        "svm_clf.fit(X_train, y_train)\n",
        "end_time_svm = time.time()\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "\n",
        "time_trained_svm = end_time_svm - start_time_svm\n",
        "print(f\"Training Time: {time_trained_svm:.2f} seconds\")\n",
        "\n",
        "# model evaluation\n",
        "train_accurarcy_svm = accuracy_score(y_train, svm_clf.predict(X_train))\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"Training Accuracy: {train_accurarcy_svm:.4f}\")\n",
        "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "-tlBdSFa5skZ",
        "outputId": "3583fe70-374c-446e-c995-6e1f122d5318"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train Time</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>1.055034</td>\n",
              "      <td>0.905576</td>\n",
              "      <td>0.906785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.919990</td>\n",
              "      <td>0.898549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM</td>\n",
              "      <td>5.384274</td>\n",
              "      <td>0.904955</td>\n",
              "      <td>0.905086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model  Train Time  Train Accuracy  Test Accuracy\n",
              "0  Logistic Regression    1.055034        0.905576       0.906785\n",
              "1                  KNN    0.006000        0.919990       0.898549\n",
              "2                  SVM    5.384274        0.904955       0.905086"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "perf_df = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'KNN', 'SVM'],\n",
        "    'Train Time': [time_trained_log_reg, time_trained_knn, time_trained_svm],\n",
        "    'Train Accuracy': [train_accurarcy_log_reg, train_accuracy_knn, train_accurarcy_svm],\n",
        "    'Test Accuracy': [accuracy_log_reg, accuracy_knn, accuracy_svm]\n",
        "})\n",
        "\n",
        "perf_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WI6ThlWvwtel"
      },
      "outputs": [],
      "source": [
        "# From the result df above, we can tell that KNN takes the shortest time for training, but its acc score is the worst. SVM took the most time but its score is worse than logistic regression.\n",
        "# Logistic regression has a faster training time with the best test accurarcy, which could be the optimal solution for our problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr7zIBahwtP5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V1zzwLV5skZ"
      },
      "source": [
        "### Problem 11: Improving the Model\n",
        "\n",
        "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
        "\n",
        "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
        "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
        "- Adjust your performance metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3Eh1_Twd5skZ"
      },
      "outputs": [],
      "source": [
        "# More feature engineering and exploration. For example, should we keep the gender feature? Why or why not?\n",
        "# I think my answer would be no. Gender won't be a good feature that has a strong correlation. Since different people can have difference decisions on keeping the term deposit\n",
        "# without a gender distinction. Both male and females have the potential to accept it or refuse it.\n",
        "# In my experiments above, I already think of the features that would serve robust and strong params for prediction, so I don't want to modify this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AW4ltXtr5skZ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning and grid search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdnUx5945skZ",
        "outputId": "599a374c-56be-4484-acef-bf7fb0e9bff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'n_neighbors': 9, 'weights': 'uniform'}\n",
            "Best cross-validation score: 0.9019479826576815\n"
          ]
        }
      ],
      "source": [
        "# KNN tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search_knn.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search_knn.best_score_)\n",
        "\n",
        "# from the tuning result, I can see n_neighbors=9 with uniform weight would give the optimal result. The tuning actually increases our accurarcy from 0.8985 to 0.9019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZC9lAHF5skZ",
        "outputId": "342e2b12-96d1-4f2c-e090-12478945d80d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Grid search with 5-fold cross-validation\u001b[39;00m\n\u001b[32m     17\u001b[39m grid_search_svc = GridSearchCV(svc, param_grid, cv=\u001b[32m5\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m,verbose=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mgrid_search_svc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Results\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest Parameters:\u001b[39m\u001b[33m\"\u001b[39m, grid_search_svc.best_params_)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# SVM tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = [\n",
        "    {'kernel': ['linear'],},\n",
        "    {'kernel': ['rbf'],},\n",
        "#    {'kernel': ['poly'], 'degree': [2,3]},\n",
        "    {'kernel': ['sigmoid']}\n",
        "]\n",
        "\n",
        "# Create the SVC model\n",
        "svc = SVC()\n",
        "\n",
        "# Grid search with 5-fold cross-validation\n",
        "grid_search_svc = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1,verbose=2)\n",
        "grid_search_svc.fit(X_train, y_train)\n",
        "\n",
        "# Results\n",
        "print(\"Best Parameters:\", grid_search_svc.best_params_)\n",
        "print(f\"Best Cross-Validation Score: {grid_search_svc.best_score_:.4f}\")\n",
        "\n",
        "# not sure why this takes forever to train, so I can give it up.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5aSSM2pe5skc"
      },
      "outputs": [],
      "source": [
        "# Adjust your performance metric\n",
        "# the classification report already gives matrix on different metrics, I don't think I can have other metrics that can best evaluate the model' performance other than that\n",
        "# I will keep using the accuracy score since this is the most common and evident one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLgMvcDK5skc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgA7h6u25skc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdg1nW-l5skc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90gj_4WZ5skc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZP0Huv25skc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQayabGB5skc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRqhMZMv5skc"
      },
      "source": [
        "##### Questions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
